{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Añade la raíz del proyecto al path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.adaBoost import train_adaboost\n",
    "from models.decisionTree import train_decision_tree\n",
    "from models.randomForest import train_random_forest\n",
    "from models.catBoost import CatBoostRegressor\n",
    "from models.xgBoost import xgBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de train\n",
    "AAPL_train_val = pd.read_csv(\"../data/processed/AAPL_train.csv\")\n",
    "AMZN_train_val = pd.read_csv(\"../data/processed/AMZN_train.csv\")\n",
    "GOOGL_train_val = pd.read_csv(\"../data/processed/GOOGL_train.csv\")\n",
    "MSFT_train_val = pd.read_csv(\"../data/processed/MSFT_train.csv\")\n",
    "NVDA_train_val = pd.read_csv(\"../data/processed/NVDA_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de test\n",
    "AAPL_test = pd.read_csv(\"../data/processed/AAPL_test.csv\")\n",
    "AMZN_test = pd.read_csv(\"../data/processed/AMZN_test.csv\")\n",
    "GOOGL_test = pd.read_csv(\"../data/processed/GOOGL_test.csv\")\n",
    "MSFT_test = pd.read_csv(\"../data/processed/MSFT_test.csv\")\n",
    "NVDA_test = pd.read_csv(\"../data/processed/NVDA_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar en train y val\n",
    "AAPL_train, AAPL_val  = train_test_split(AAPL_train_val, test_size=0.2, random_state=42, shuffle=True) \n",
    "AMZN_train, AMZN_val  = train_test_split(AMZN_train_val, test_size=0.2, random_state=42, shuffle=True)\n",
    "GOOGL_train, GOOGL_val  = train_test_split(GOOGL_train_val, test_size=0.2, random_state=42, shuffle=True)\n",
    "MSFT_train, MSFT_val  = train_test_split(MSFT_train_val, test_size=0.2, random_state=42, shuffle=True)\n",
    "NVDA_train, NVDA_val  = train_test_split(NVDA_train_val, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa en cada dataset\n",
    "AAPL_y_train = AAPL_train['ChangeRatio']\n",
    "AAPL_X_train = AAPL_train.drop(columns=['ChangeRatio'])\n",
    "AAPL_y_valid = AAPL_val['ChangeRatio']\n",
    "AAPL_X_valid = AAPL_val.drop(columns=['ChangeRatio'])\n",
    "AMZN_y_train = AMZN_train['ChangeRatio']\n",
    "AMZN_X_train = AMZN_train.drop(columns=['ChangeRatio'])\n",
    "AMZN_y_valid = AMZN_val['ChangeRatio']\n",
    "AMZN_X_valid = AMZN_val.drop(columns=['ChangeRatio'])\n",
    "GOOGL_y_train = GOOGL_train['ChangeRatio']\n",
    "GOOGL_X_train = GOOGL_train.drop(columns=['ChangeRatio'])\n",
    "GOOGL_y_valid = GOOGL_val['ChangeRatio']\n",
    "GOOGL_X_valid = GOOGL_val.drop(columns=['ChangeRatio'])\n",
    "MSFT_y_train = MSFT_train['ChangeRatio']\n",
    "MSFT_X_train = MSFT_train.drop(columns=['ChangeRatio'])\n",
    "MSFT_y_valid = MSFT_val['ChangeRatio']\n",
    "MSFT_X_valid = MSFT_val.drop(columns=['ChangeRatio'])\n",
    "NVDA_y_train = NVDA_train['ChangeRatio']\n",
    "NVDA_X_train = NVDA_train.drop(columns=['ChangeRatio'])\n",
    "NVDA_y_valid = NVDA_val['ChangeRatio']\n",
    "NVDA_X_valid = NVDA_val.drop(columns=['ChangeRatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saca los test\n",
    "AAPL_y_test = AAPL_test['ChangeRatio']\n",
    "AAPL_X_test = AAPL_test.drop(columns=['ChangeRatio'])\n",
    "AMZN_y_test = AMZN_test['ChangeRatio']\n",
    "AMZN_X_test = AMZN_test.drop(columns=['ChangeRatio'])\n",
    "GOOGL_y_test = GOOGL_test['ChangeRatio']\n",
    "GOOGL_X_test = GOOGL_test.drop(columns=['ChangeRatio'])\n",
    "MSFT_y_test = MSFT_test['ChangeRatio']\n",
    "MSFT_X_test = MSFT_test.drop(columns=['ChangeRatio'])\n",
    "NVDA_y_test = NVDA_test['ChangeRatio']\n",
    "NVDA_X_test = NVDA_test.drop(columns=['ChangeRatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escala los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "AAPL_X_train = scaler.fit_transform(AAPL_X_train)\n",
    "AAPL_X_valid = scaler.transform(AAPL_X_valid)\n",
    "AAPL_X_test = scaler.transform(AAPL_X_test)\n",
    "AMZN_X_train = scaler.fit_transform(AMZN_X_train)\n",
    "AMZN_X_valid = scaler.transform(AMZN_X_valid)\n",
    "AMZN_X_test = scaler.transform(AMZN_X_test)\n",
    "GOOGL_X_train = scaler.fit_transform(GOOGL_X_train)\n",
    "GOOGL_X_valid = scaler.transform(GOOGL_X_valid)\n",
    "GOOGL_X_test = scaler.transform(GOOGL_X_test)\n",
    "MSFT_X_train = scaler.fit_transform(MSFT_X_train)\n",
    "MSFT_X_valid = scaler.transform(MSFT_X_valid)\n",
    "MSFT_X_test = scaler.transform(MSFT_X_test)\n",
    "NVDA_X_train = scaler.fit_transform(NVDA_X_train)\n",
    "NVDA_X_valid = scaler.transform(NVDA_X_valid)\n",
    "NVDA_X_test = scaler.transform(NVDA_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para guardar los modelos \n",
    "AAPL_models = {\n",
    "    'XGBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'CATBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'DECISION_TREE': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'RANDOM_FOREST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'ADABOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "}\n",
    "AMZN_models = {\n",
    "    'XGBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'CATBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'DECISION_TREE': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'RANDOM_FOREST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'ADABOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "}\n",
    "\n",
    "GOOGL_models = {\n",
    "    'XGBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'CATBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'DECISION_TREE': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'RANDOM_FOREST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'ADABOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "}\n",
    "\n",
    "MSFT_models = {\n",
    "    'XGBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'CATBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'DECISION_TREE': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'RANDOM_FOREST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'ADABOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "}\n",
    "\n",
    "NVDA_models = {\n",
    "    'XGBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'CATBOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'DECISION_TREE': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'RANDOM_FOREST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "    'ADABOOST': {\n",
    "        'model': None,\n",
    "        'mse': None,\n",
    "        'r2': None\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    }
   ],
   "source": [
    "AAPL_xb= xgBoostRegressor(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n",
    "AMZN_xb = xgBoostRegressor(AMZN_X_train, AMZN_y_train, AMZN_X_valid, AMZN_y_valid)\n",
    "GOOGL_xb = xgBoostRegressor(GOOGL_X_train, GOOGL_y_train, GOOGL_X_valid, GOOGL_y_valid)\n",
    "MSFT_xb = xgBoostRegressor(MSFT_X_train, MSFT_y_train, MSFT_X_valid, MSFT_y_valid)\n",
    "NVDA_xb = xgBoostRegressor(NVDA_X_train, NVDA_y_train, NVDA_X_valid, NVDA_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL xgBoostRegressor mse: 5.480931050331529\n",
      "AAPL xgBoostRegressor r2: 0.018300818762016946\n",
      "AMZN xgBoostRegressor mse: 8.824223799220604\n",
      "AMZN xgBoostRegressor r2: 0.0027883364658861653\n",
      "GOOGL xgBoostRegressor mse: 3.8407530804767007\n",
      "GOOGL xgBoostRegressor r2: -0.018315774424533693\n",
      "MSFT xgBoostRegressor mse: 2.973173447681935\n",
      "MSFT xgBoostRegressor r2: 0.07420853411668049\n",
      "NVDA xgBoostRegressor mse: 10.717627163931216\n",
      "NVDA xgBoostRegressor r2: -0.006721107114996405\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "AAPL_xb_model, mse, r2 = AAPL_xb.get_trained_model()\n",
    "print(f\"AAPL xgBoostRegressor mse: {mse}\")\n",
    "print(f\"AAPL xgBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AAPL_models['XGBOOST']['model'] = AAPL_xb_model\n",
    "AAPL_models['XGBOOST']['mse'] = mse\n",
    "AAPL_models['XGBOOST']['r2'] = r2\n",
    "\n",
    "AMZN_xb_model, mse, r2 = AMZN_xb.get_trained_model()\n",
    "print(f\"AMZN xgBoostRegressor mse: {mse}\")\n",
    "print(f\"AMZN xgBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AMZN_models['XGBOOST']['model'] = AMZN_xb_model\n",
    "AMZN_models['XGBOOST']['mse'] = mse\n",
    "AMZN_models['XGBOOST']['r2'] = r2\n",
    "\n",
    "GOOGL_xb_model, mse, r2 = GOOGL_xb.get_trained_model()\n",
    "print(f\"GOOGL xgBoostRegressor mse: {mse}\")\n",
    "print(f\"GOOGL xgBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "GOOGL_models['XGBOOST']['model'] = GOOGL_xb_model\n",
    "GOOGL_models['XGBOOST']['mse'] = mse\n",
    "GOOGL_models['XGBOOST']['r2'] = r2\n",
    "\n",
    "MSFT_xb_model, mse, r2 = MSFT_xb.get_trained_model()\n",
    "print(f\"MSFT xgBoostRegressor mse: {mse}\")\n",
    "print(f\"MSFT xgBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "MSFT_models['XGBOOST']['model'] = MSFT_xb_model\n",
    "MSFT_models['XGBOOST']['mse'] = mse\n",
    "MSFT_models['XGBOOST']['r2'] = r2\n",
    "\n",
    "NVDA_xb_model, mse, r2 = NVDA_xb.get_trained_model()\n",
    "print(f\"NVDA xgBoostRegressor mse: {mse}\")\n",
    "print(f\"NVDA xgBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "NVDA_models['XGBOOST']['model'] = NVDA_xb_model\n",
    "NVDA_models['XGBOOST']['mse'] = mse\n",
    "NVDA_models['XGBOOST']['r2'] = r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_cb = CatBoostRegressor(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n",
    "AMZN_cb = CatBoostRegressor(AMZN_X_train, AMZN_y_train, AMZN_X_valid, AMZN_y_valid)\n",
    "GOOGL_cb = CatBoostRegressor(GOOGL_X_train, GOOGL_y_train, GOOGL_X_valid, GOOGL_y_valid)\n",
    "MSFT_cb = CatBoostRegressor(MSFT_X_train, MSFT_y_train, MSFT_X_valid, MSFT_y_valid)\n",
    "NVDA_cb = CatBoostRegressor(NVDA_X_train, NVDA_y_train, NVDA_X_valid, NVDA_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL CatBoostRegressor mse: 5.238848837271757\n",
      "AAPL CatBoostRegressor r2: 0.06166058887601655\n",
      "AMZN CatBoostRegressor mse: 8.099252235518492\n",
      "AMZN CatBoostRegressor r2: 0.08471623352558733\n",
      "GOOGL CatBoostRegressor mse: 3.793226597653903\n",
      "GOOGL CatBoostRegressor r2: -0.005714868782517035\n",
      "MSFT CatBoostRegressor mse: 2.988221407171245\n",
      "MSFT CatBoostRegressor r2: 0.06952287661323997\n",
      "NVDA CatBoostRegressor mse: 10.728610293170673\n",
      "NVDA CatBoostRegressor r2: -0.007752767188482057\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "AAPL_cb_model, mse, r2 = AAPL_cb.get_trained_model()\n",
    "print(f\"AAPL CatBoostRegressor mse: {mse}\")\n",
    "print(f\"AAPL CatBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AAPL_models['CATBOOST']['model'] = AAPL_cb_model\n",
    "AAPL_models['CATBOOST']['mse'] = mse\n",
    "AAPL_models['CATBOOST']['r2'] = r2\n",
    "\n",
    "AMZN_cb_model, mse, r2 = AMZN_cb.get_trained_model()\n",
    "print(f\"AMZN CatBoostRegressor mse: {mse}\")\n",
    "print(f\"AMZN CatBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AMZN_models['CATBOOST']['model'] = AMZN_cb_model\n",
    "AMZN_models['CATBOOST']['mse'] = mse\n",
    "AMZN_models['CATBOOST']['r2'] = r2\n",
    "\n",
    "GOOGL_cb_model, mse, r2 = GOOGL_cb.get_trained_model()\n",
    "print(f\"GOOGL CatBoostRegressor mse: {mse}\")\n",
    "print(f\"GOOGL CatBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "GOOGL_models['CATBOOST']['model'] = GOOGL_cb_model\n",
    "GOOGL_models['CATBOOST']['mse'] = mse\n",
    "GOOGL_models['CATBOOST']['r2'] = r2\n",
    "\n",
    "MSFT_cb_model, mse, r2 = MSFT_cb.get_trained_model()\n",
    "print(f\"MSFT CatBoostRegressor mse: {mse}\")\n",
    "print(f\"MSFT CatBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "MSFT_models['CATBOOST']['model'] = MSFT_cb_model\n",
    "MSFT_models['CATBOOST']['mse'] = mse\n",
    "MSFT_models['CATBOOST']['r2'] = r2\n",
    "\n",
    "NVDA_cb_model, mse, r2 = NVDA_cb.get_trained_model()\n",
    "print(f\"NVDA CatBoostRegressor mse: {mse}\")\n",
    "print(f\"NVDA CatBoostRegressor r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "NVDA_models['CATBOOST']['model'] = NVDA_cb_model\n",
    "NVDA_models['CATBOOST']['mse'] = mse\n",
    "NVDA_models['CATBOOST']['r2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión (Validación):\n",
      "MSE: 5.59\n",
      "R²: -0.00\n",
      "AAPL DecisionTree mse: 5.586582031502136\n",
      "AAPL DecisionTree r2: -0.0006225139272166835\n",
      "Árbol de Decisión (Validación):\n",
      "MSE: 8.88\n",
      "R²: -0.00\n",
      "AMZN DecisionTree mse: 8.883427853167097\n",
      "AMZN DecisionTree r2: -0.0039022206264172077\n",
      "Árbol de Decisión (Validación):\n",
      "MSE: 3.58\n",
      "R²: 0.05\n",
      "GOOGL DecisionTree mse: 3.5795984366167133\n",
      "GOOGL DecisionTree r2: 0.05092530612257584\n",
      "Árbol de Decisión (Validación):\n",
      "MSE: 3.40\n",
      "R²: -0.06\n",
      "MSFT DecisionTree mse: 3.3958592125479887\n",
      "MSFT DecisionTree r2: -0.05740803005264228\n",
      "Árbol de Decisión (Validación):\n",
      "MSE: 10.66\n",
      "R²: -0.00\n",
      "NVDA DecisionTree mse: 10.660540160727406\n",
      "NVDA DecisionTree r2: -0.001358848269061852\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "AAPL_dt_model, mse, r2 = train_decision_tree(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n",
    "print(f\"AAPL DecisionTree mse: {mse}\")\n",
    "print(f\"AAPL DecisionTree r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AAPL_models['DECISION_TREE']['model'] = AAPL_dt_model\n",
    "AAPL_models['DECISION_TREE']['mse'] = mse\n",
    "AAPL_models['DECISION_TREE']['r2'] = r2\n",
    "\n",
    "AMZN_dt_model, mse, r2 = train_decision_tree(AMZN_X_train, AMZN_y_train, AMZN_X_valid, AMZN_y_valid)\n",
    "print(f\"AMZN DecisionTree mse: {mse}\")\n",
    "print(f\"AMZN DecisionTree r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AMZN_models['DECISION_TREE']['model'] = AMZN_dt_model\n",
    "AMZN_models['DECISION_TREE']['mse'] = mse\n",
    "AMZN_models['DECISION_TREE']['r2'] = r2\n",
    "\n",
    "GOOGL_dt_model, mse, r2 = train_decision_tree(GOOGL_X_train, GOOGL_y_train, GOOGL_X_valid, GOOGL_y_valid)\n",
    "print(f\"GOOGL DecisionTree mse: {mse}\")\n",
    "print(f\"GOOGL DecisionTree r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "GOOGL_models['DECISION_TREE']['model'] = GOOGL_dt_model\n",
    "GOOGL_models['DECISION_TREE']['mse'] = mse\n",
    "GOOGL_models['DECISION_TREE']['r2'] = r2\n",
    "\n",
    "MSFT_dt_model, mse, r2 = train_decision_tree(MSFT_X_train, MSFT_y_train, MSFT_X_valid, MSFT_y_valid)\n",
    "print(f\"MSFT DecisionTree mse: {mse}\")\n",
    "print(f\"MSFT DecisionTree r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "MSFT_models['DECISION_TREE']['model'] = MSFT_dt_model\n",
    "MSFT_models['DECISION_TREE']['mse'] = mse\n",
    "MSFT_models['DECISION_TREE']['r2'] = r2\n",
    "\n",
    "NVDA_dt_model, mse, r2 = train_decision_tree(NVDA_X_train, NVDA_y_train, NVDA_X_valid, NVDA_y_valid)\n",
    "print(f\"NVDA DecisionTree mse: {mse}\")\n",
    "print(f\"NVDA DecisionTree r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "NVDA_models['DECISION_TREE']['model'] = NVDA_dt_model\n",
    "NVDA_models['DECISION_TREE']['mse'] = mse\n",
    "NVDA_models['DECISION_TREE']['r2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m AAPL_rf_model, mse, r2 \u001b[38;5;241m=\u001b[39m train_random_forest(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL RandomForest mse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL RandomForest r2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Datamining/Proyecto3DM/models/randomForest.py:13\u001b[0m, in \u001b[0;36mtrain_random_forest\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     11\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     12\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(forest, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     16\u001b[0m best_model\u001b[38;5;241m.\u001b[39mset_params(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m         clone(base_estimator),\n\u001b[1;32m    973\u001b[0m         X,\n\u001b[1;32m    974\u001b[0m         y,\n\u001b[1;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    479\u001b[0m ]\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m )(\n\u001b[1;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    493\u001b[0m         t,\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    495\u001b[0m         X,\n\u001b[1;32m    496\u001b[0m         y,\n\u001b[1;32m    497\u001b[0m         sample_weight,\n\u001b[1;32m    498\u001b[0m         i,\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:197\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    190\u001b[0m         X,\n\u001b[1;32m    191\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    198\u001b[0m         X,\n\u001b[1;32m    199\u001b[0m         y,\n\u001b[1;32m    200\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    201\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "AAPL_rf_model, mse, r2 = train_random_forest(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n",
    "print(f\"AAPL RandomForest mse: {mse}\")\n",
    "print(f\"AAPL RandomForest r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AAPL_models['RANDOM_FOREST']['model'] = AAPL_rf_model\n",
    "AAPL_models['RANDOM_FOREST']['mse'] = mse\n",
    "AAPL_models['RANDOM_FOREST']['r2'] = r2\n",
    "\n",
    "AMZN_rf_model, mse, r2 = train_random_forest(AMZN_X_train, AMZN_y_train, AMZN_X_valid, AMZN_y_valid)\n",
    "print(f\"AMZN RandomForest mse: {mse}\")\n",
    "print(f\"AMZN RandomForest r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AMZN_models['RANDOM_FOREST']['model'] = AMZN_rf_model\n",
    "AMZN_models['RANDOM_FOREST']['mse'] = mse\n",
    "AMZN_models['RANDOM_FOREST']['r2'] = r2\n",
    "\n",
    "GOOGL_rf_model, mse, r2 = train_random_forest(GOOGL_X_train, GOOGL_y_train, GOOGL_X_valid, GOOGL_y_valid)\n",
    "print(f\"GOOGL RandomForest mse: {mse}\")\n",
    "print(f\"GOOGL RandomForest r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "GOOGL_models['RANDOM_FOREST']['model'] = GOOGL_rf_model \n",
    "GOOGL_models['RANDOM_FOREST']['mse'] = mse\n",
    "GOOGL_models['RANDOM_FOREST']['r2'] = r2\n",
    "\n",
    "MSFT_rf_model, mse, r2 = train_random_forest(MSFT_X_train, MSFT_y_train, MSFT_X_valid, MSFT_y_valid)\n",
    "print(f\"MSFT RandomForest mse: {mse}\")\n",
    "print(f\"MSFT RandomForest r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "MSFT_models['RANDOM_FOREST']['model'] = MSFT_rf_model\n",
    "MSFT_models['RANDOM_FOREST']['mse'] = mse\n",
    "MSFT_models['RANDOM_FOREST']['r2'] = r2\n",
    "\n",
    "NVDA_rf_model, mse, r2 = train_random_forest(NVDA_X_train, NVDA_y_train, NVDA_X_valid, NVDA_y_valid)\n",
    "print(f\"NVDA RandomForest mse: {mse}\")\n",
    "print(f\"NVDA RandomForest r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "NVDA_models['RANDOM_FOREST']['model'] = NVDA_rf_model\n",
    "NVDA_models['RANDOM_FOREST']['mse'] = mse\n",
    "NVDA_models['RANDOM_FOREST']['r2'] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# AdaBoost\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m AAPL_ab_model, mse, r2 \u001b[38;5;241m=\u001b[39m train_adaboost(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL AdaBoost mse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL AdaBoost r2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Datamining/Proyecto3DM/models/adaBoost.py:11\u001b[0m, in \u001b[0;36mtrain_adaboost\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m      9\u001b[0m ada \u001b[38;5;241m=\u001b[39m AdaBoostRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     10\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(ada, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     12\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     14\u001b[0m best_model\u001b[38;5;241m.\u001b[39mset_params(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m         clone(base_estimator),\n\u001b[1;32m    973\u001b[0m         X,\n\u001b[1;32m    974\u001b[0m         y,\n\u001b[1;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:167\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    164\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[1;32m    168\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:1068\u001b[0m, in \u001b[0;36mAdaBoostRegressor._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m   1066\u001b[0m X_ \u001b[38;5;241m=\u001b[39m _safe_indexing(X, bootstrap_idx)\n\u001b[1;32m   1067\u001b[0m y_ \u001b[38;5;241m=\u001b[39m _safe_indexing(y, bootstrap_idx)\n\u001b[0;32m-> 1068\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X_, y_)\n\u001b[1;32m   1069\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m   1071\u001b[0m error_vect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y_predict \u001b[38;5;241m-\u001b[39m y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:1404\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1404\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1405\u001b[0m         X,\n\u001b[1;32m   1406\u001b[0m         y,\n\u001b[1;32m   1407\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1408\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1409\u001b[0m     )\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "AAPL_ab_model, mse, r2 = train_adaboost(AAPL_X_train, AAPL_y_train, AAPL_X_valid, AAPL_y_valid)\n",
    "print(f\"AAPL AdaBoost mse: {mse}\")\n",
    "print(f\"AAPL AdaBoost r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AAPL_models['ADABOOST']['model'] = AAPL_ab_model\n",
    "AAPL_models['ADABOOST']['mse'] = mse\n",
    "AAPL_models['ADABOOST']['r2'] = r2\n",
    "\n",
    "AMZN_ab_model, mse, r2 = train_adaboost(AMZN_X_train, AMZN_y_train, AMZN_X_valid, AMZN_y_valid)\n",
    "print(f\"AMZN AdaBoost mse: {mse}\")\n",
    "print(f\"AMZN AdaBoost r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "AMZN_models['ADABOOST']['model'] = AMZN_ab_model\n",
    "AMZN_models['ADABOOST']['mse'] = mse\n",
    "AMZN_models['ADABOOST']['r2'] = r2\n",
    "\n",
    "GOOGL_ab_model, mse, r2 = train_adaboost(GOOGL_X_train, GOOGL_y_train, GOOGL_X_valid, GOOGL_y_valid)\n",
    "print(f\"GOOGL AdaBoost mse: {mse}\")\n",
    "print(f\"GOOGL AdaBoost r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "GOOGL_models['ADABOOST']['model'] = GOOGL_ab_model\n",
    "GOOGL_models['ADABOOST']['mse'] = mse\n",
    "GOOGL_models['ADABOOST']['r2'] = r2\n",
    "\n",
    "MSFT_ab_model, mse, r2 = train_adaboost(MSFT_X_train, MSFT_y_train, MSFT_X_valid, MSFT_y_valid)\n",
    "print(f\"MSFT AdaBoost mse: {mse}\")\n",
    "print(f\"MSFT AdaBoost r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "MSFT_models['ADABOOST']['model'] = MSFT_ab_model\n",
    "MSFT_models['ADABOOST']['mse'] = mse\n",
    "MSFT_models['ADABOOST']['r2'] = r2\n",
    "\n",
    "NVDA_ab_model, mse, r2 = train_adaboost(NVDA_X_train, NVDA_y_train, NVDA_X_valid, NVDA_y_valid)\n",
    "print(f\"NVDA AdaBoost mse: {mse}\")\n",
    "print(f\"NVDA AdaBoost r2: {r2}\")\n",
    "# Guarda el modelo en el diccionario\n",
    "NVDA_models['ADABOOST']['model'] = NVDA_ab_model\n",
    "NVDA_models['ADABOOST']['mse'] = mse\n",
    "NVDA_models['ADABOOST']['r2'] = r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def model_evaluation(model, X_test_scaled, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and returns the predictions.\n",
    "    \"\"\" \n",
    "    apple_data_test_with_date = pd.read_csv('../data/raw/AAPL_with_SP500.csv')\n",
    "    apple_data_test_with_date = apple_data_test_with_date[apple_data_test_with_date['Date'] >= '2025-03-01']\n",
    "    apple_data_test_with_date = apple_data_test_with_date[apple_data_test_with_date['Date'] <= '2025-03-31']\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)  \n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\")\n",
    "\n",
    "    print(f\"Predicciones positivas reales: {np.sum(y_test > 0)}\")\n",
    "    print(f\"Predicciones positivas predichas: {np.sum(y_pred > 0)}\")\n",
    "\n",
    "    print(f\"Predicciones negativas reales: {np.sum(y_test < 0)}\")\n",
    "    print(f\"Predicciones negativas predichas: {np.sum(y_pred < 0)}\")\n",
    "\n",
    "    accuracy = np.sum((y_test > 0) & (y_pred > 0)) + np.sum((y_test < 0) & (y_pred < 0))\n",
    "    accuracy = accuracy / len(y_test)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Crear un DataFrame con fechas y valores reales y predichos\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': apple_data_test_with_date['Date'].values[:len(y_test)],\n",
    "        'Real': y_test.values,\n",
    "        'Predicción': y_pred\n",
    "    })\n",
    "\n",
    "    # Convertir la columna de fecha a datetime\n",
    "    result_df['Date'] = pd.to_datetime(result_df['Date'])\n",
    "\n",
    "    # Graficar los valores reales y predichos a lo largo del tiempo\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(result_df['Date'], result_df['Real'], label='Valores Reales', marker='o')\n",
    "    plt.plot(result_df['Date'], result_df['Predicción'], label='Valores Predichos', marker='x')\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Cambio Ratio')\n",
    "    plt.title('Predicción vs Valores Reales - Marzo 2025')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Gráfico de dispersión\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel('Valores Reales')\n",
    "    plt.ylabel('Valores Predichos')\n",
    "    plt.title('Regresión Lineal: Valores Reales vs. Valores Predichos - Marzo 2025')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def guardar_mejor_modelo(models_dict, ruta_guardado):\n",
    "    \"\"\"\n",
    "    Selecciona el modelo con el menor MSE de un diccionario de modelos y lo guarda en un archivo.\n",
    "    \n",
    "    Args:\n",
    "        models_dict (dict): Diccionario con estructura {nombre_modelo: {'model': modelo, 'mse': valor_mse}}.\n",
    "        ruta_guardado (str): Ruta donde se guardará el modelo con menor MSE.\n",
    "    \"\"\"\n",
    "    mejor_modelo = None\n",
    "    mejor_mse = float('inf')\n",
    "    nombre_mejor_modelo = None\n",
    "\n",
    "    for model_name, model_info in models_dict.items():\n",
    "        if model_info['mse'] < mejor_mse:\n",
    "            mejor_mse = model_info['mse']\n",
    "            mejor_modelo = model_info['model']\n",
    "            nombre_mejor_modelo = model_name\n",
    "\n",
    "    if mejor_modelo is not None:\n",
    "        joblib.dump(mejor_modelo, ruta_guardado)\n",
    "        print(f\"Mejor modelo: {nombre_mejor_modelo}\")\n",
    "        print(f\"Mejor mse: {mejor_mse}\")\n",
    "        print(f\"Modelo guardado en: {ruta_guardado}\")\n",
    "    else:\n",
    "        print(\"No se encontró ningún modelo válido.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escoge el mejor modelo para cada accion\n",
    "guardar_mejor_modelo(AAPL_models, \"../models/trained/AAPL_best_model.pkl\")\n",
    "guardar_mejor_modelo(AMZN_models, \"../models/trained/AMZN_best_model.pkl\")\n",
    "guardar_mejor_modelo(GOOGL_models, \"../models/trained/GOOGL_best_model.pkl\")\n",
    "guardar_mejor_modelo(MSFT_models, \"../models/trained/MSFT_best_model.pkl\")\n",
    "guardar_mejor_modelo(NVDA_models, \"../models/trained/NVDA_best_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
